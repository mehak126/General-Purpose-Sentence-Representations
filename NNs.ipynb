{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow.python.ops import lookup_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = '../data/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLI_create_dataset(vocab_file,vocab_table ,batch_size):\n",
    "    dataset = tf.data.TextLineDataset(vocab_file)\n",
    "    dataset = dataset.map(lambda sentence: (tf.string_split([sentence])).values )\n",
    "    dataset = dataset.map(lambda words: (vocab_table.lookup(words), tf.size(words)) )\n",
    "    dataset = dataset.padded_batch(batch_size = batch_size, padded_shapes = ([None], [] ))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.Model):\n",
    "    def __init__(self, V, d, init):\n",
    "        super(Embedding, self).__init__()\n",
    "#         self.W = tfe.Variable(tf.random_uniform(minval=-1.0, maxval=1.0, shape=[V, d]))\n",
    "        self.W = tfe.Variable(init)\n",
    "    \n",
    "    def call(self, word_indexes):\n",
    "        return tf.nn.embedding_lookup(self.W, word_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticRNN(tf.keras.Model):\n",
    "    def __init__(self, h, cell):\n",
    "        super(StaticRNN, self).__init__()\n",
    "        if cell == 'lstm':\n",
    "            self.cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=h)\n",
    "        elif cell == 'gru':\n",
    "            self.cell = tf.nn.rnn_cell.GRUCell(num_units=h)\n",
    "        else:\n",
    "            self.cell = tf.nn.rnn_cell.BasicRNNCell(num_units=h)\n",
    "        \n",
    "        \n",
    "    def call(self, word_vectors, num_words, state, init_state):\n",
    "        word_vectors_time = tf.unstack(word_vectors, axis=1)\n",
    "        if state:\n",
    "            outputs, final_state = tf.nn.static_rnn(cell=self.cell, initial_state = init_state,  sequence_length=num_words, inputs=word_vectors_time, dtype=tf.float32)\n",
    "        else:\n",
    "            outputs, final_state = tf.nn.static_rnn(cell=self.cell,  sequence_length=num_words, inputs=word_vectors_time, dtype=tf.float32)\n",
    "        return outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, V, d, h, cell):\n",
    "        super(Encoder, self).__init__()\n",
    "        init = tf.random_uniform(minval=-1.0, maxval=1.0, shape=[V, d])\n",
    "        self.word_embedding = Embedding(V, d, init)\n",
    "        self.rnn = StaticRNN(h, cell)\n",
    "\n",
    "        \n",
    "    def call(self, datum, lens, state, init_state):\n",
    "        word_vectors = self.word_embedding(datum)        \n",
    "        logits, final_state = self.rnn(word_vectors, lens, state, init_state)\n",
    "        batch_outputs = []\n",
    "        for i in range(int(tf.size(lens))):\n",
    "            sen_len = int(lens[i])\n",
    "            batch_outputs.append(logits[sen_len-1][i])\n",
    "\n",
    "#         return logits[-1], final_state\n",
    "        return tf.convert_to_tensor(batch_outputs), final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_state = tf.convert_to_tensor(np.zeros(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_table = lookup_ops.index_table_from_file(vocab_file, default_value = 0)\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NLI_create_dataset(vocab_file,vocab_table ,30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(30000, 256, 512, 'gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x11ce52e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = '../nmt_encoder'\n",
    "root = tfe.Checkpoint(optimizer=opt, model=encoder, optimizer_step=tf.train.get_or_create_global_step())\n",
    "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, state = encoder(datum[0], datum[1], False, dummy_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(r1, r2):\n",
    "    return cosine_similarity(r1.reshape(1,-1), r2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=5, metric = similarity).fit(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnbrs = nbrs.kneighbors(word_embeddings, 5, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_table = Counter()\n",
    "with open(vocab_file, 'r') as fr:\n",
    "    for index, line in enumerate(fr):\n",
    "        vocab_table[len(vocab_table)] =  line.rstrip().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nearest_neighbours.txt', 'w') as fw:\n",
    "    for i in range(len(vocab_table)):\n",
    "        fw.write(vocab_table[i])\n",
    "        for j in range(5):\n",
    "            fw.write(', ' +  vocab_table[nnbrs[i][j]] )\n",
    "        fw.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
